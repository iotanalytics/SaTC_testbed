{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YUmSzinPpWqe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\steph\\OneDrive\\Documents\\GitHub\\SaTC_testbed\\stepstone_attack\\attack_detection\\fastsst\\sst.py:199: NumbaPerformanceWarning: \u001b[1m\u001b[1m'@' is faster on contiguous arrays, called on (array(float64, 2d, A), array(float64, 2d, A))\u001b[0m\u001b[0m\n",
            "  _, s, _ = np.linalg.svd(U_test[:, :n_components].T @\n",
            "C:\\Users\\steph\\anaconda3\\lib\\site-packages\\numba\\core\\typing\\npydecl.py:965: NumbaPerformanceWarning: \u001b[1m'@' is faster on contiguous arrays, called on (array(float64, 2d, A), array(float64, 2d, A))\u001b[0m\n",
            "  warnings.warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import time, datetime\n",
        "import pytz\n",
        "import pandas as pd\n",
        "\n",
        "from pandas import read_csv\n",
        "from influxdb import InfluxDBClient\n",
        "from keras.models import load_model\n",
        "from scipy.fftpack import fft\n",
        "from numba import jit\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from fastsst.util.linear_algebra import power_method, lanczos, eig_tridiag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k80vXHMN1ZJ2",
        "outputId": "5fef35f9-4600-44ab-f1a9-0f3712d9a00b"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 3] The system cannot find the path specified: '/content/drive/MyDrive/Case_Study_1_BearingFault_Data/Data_csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3100/4145553649.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'/content/drive/MyDrive/Case_Study_1_BearingFault_Data/Data_csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/MyDrive/Case_Study_1_BearingFault_Data/Data_csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# f_s, Nn, num_time_periods, dataWindow =2000, 200, 20, 400 #parameter definition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# #featuredata = np.zeros((len(os.listdir(directory))*length_data),15*num_time_periods)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/drive/MyDrive/Case_Study_1_BearingFault_Data/Data_csv'"
          ]
        }
      ],
      "source": [
        "directory = r'/content/drive/MyDrive/Case_Study_1_BearingFault_Data/Data_csv'\n",
        "os.listdir(directory)\n",
        "os.chdir('/content/drive/MyDrive/Case_Study_1_BearingFault_Data/Data_csv')\n",
        "# f_s, Nn, num_time_periods, dataWindow =2000, 200, 20, 400 #parameter definition\n",
        "# #featuredata = np.zeros((len(os.listdir(directory))*length_data),15*num_time_periods)\n",
        "# #labeldata = np.zeros(((len(os.listdir(directory))*length_data),4)\n",
        "time_len=20000\n",
        "data_arrange=np.zeros((20000,10,9))\n",
        "j=-1\n",
        "for filename in os.listdir(directory):\n",
        "  if(filename.endswith(\"csv\")):\n",
        "    j=j+1\n",
        "    print(filename)\n",
        "    dataCollectIni = read_csv(filename,header=None).iloc[::10,1:] #obtain the current waveform\n",
        "    dataCollect = dataCollectIni.values\n",
        "    dataCollect = dataCollect[:,[0,1,2,4,5,6,7,8,9]]\n",
        "    dataCollect = dataCollect.astype(float)\n",
        "    for i in range(9):\n",
        "      data_arrange[:,j,i]=dataCollect[:,i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAvsS5s57Ps9"
      },
      "outputs": [],
      "source": [
        "####### The input could only have the first decision score after the start data comes in\n",
        "\n",
        "# Code requires one full window to be imported when starting.  Anomaly Detection requires one sample \n",
        "# at a time after the first window to work.\n",
        "# Import one window from influxDB at start of program\n",
        "# Import one sampe from influxDB afterwards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCPClh0lBpYq",
        "outputId": "39fe7898-91ea-4ec5-d954-f34517d83cd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\steph\\AppData\\Local\\Temp/ipykernel_3100/3797001328.py:192: NumbaPerformanceWarning: \u001b[1m\u001b[1m'@' is faster on contiguous arrays, called on (array(float64, 2d, A), array(float64, 2d, A))\u001b[0m\u001b[0m\n",
            "  _, s, _ = np.linalg.svd(U_test[:, :n_components].T @\n",
            "C:\\Users\\steph\\anaconda3\\lib\\site-packages\\numba\\core\\typing\\npydecl.py:965: NumbaPerformanceWarning: \u001b[1m'@' is faster on contiguous arrays, called on (array(float64, 2d, A), array(float64, 2d, A))\u001b[0m\n",
            "  warnings.warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class SingularSpectrumTransformation():\n",
        "    \"\"\"SingularSpectrumTransformation class.\"\"\"\n",
        "\n",
        "    def __init__(self, win_length, x0, n_components=5, order=None, lag=None,\n",
        "                 is_scaled=False, use_lanczos=True, rank_lanczos=None, eps=1e-3):\n",
        "        \"\"\"Change point detection with Singular Spectrum Transformation.\n",
        "        Parameters\n",
        "        ----------\n",
        "        win_length : int\n",
        "            window length of Hankel matrix.\n",
        "        n_components : int\n",
        "            specify how many rank of Hankel matrix will be taken.\n",
        "        order : int\n",
        "            number of columns of Hankel matrix.\n",
        "        lag : int\n",
        "            interval between history Hankel matrix and test Hankel matrix.\n",
        "        is_scaled : bool\n",
        "            if false, min-max scaling will be applied(recommended).\n",
        "        use_lanczos : boolean\n",
        "            if true, Lanczos method will be used, which makes faster.\n",
        "        rank_lanczos : int\n",
        "            the rank which will be used for lanczos method.\n",
        "            for the detail of lanczos method, see [1].\n",
        "        eps : float\n",
        "            specify how much noise will be added to initial vector for\n",
        "            power method.\n",
        "            (FELIX: FEedback impLIcit kernel approXimation method)\n",
        "            for the detail, see [2].\n",
        "        References\n",
        "        ----------\n",
        "        [1]: Tsuyoshi Ide et al., Change-Point Detection using Krylov Subspace Learning\n",
        "        [2]: Tsuyoshi Ide, Speeding up Change-Point Detection using Matrix Compression (Japanse)\n",
        "        \"\"\"\n",
        "        self.win_length = win_length\n",
        "        self.n_components = n_components\n",
        "        self.order = order\n",
        "        self.lag = lag\n",
        "        self.is_scaled = is_scaled\n",
        "        self.use_lanczos = use_lanczos\n",
        "        self.rank_lanczos = rank_lanczos\n",
        "        self.eps = eps\n",
        "\n",
        "    def score_online(self, x):\n",
        "        \"\"\"Calculate anomaly score (offline).\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : 1d numpy array\n",
        "            input time series data.\n",
        "        Returns\n",
        "        -------\n",
        "        score : 1d array\n",
        "            change point score.\n",
        "        \"\"\"\n",
        "        if self.order is None:\n",
        "            # rule of thumb\n",
        "            self.order = self.win_length\n",
        "        if self.lag is None:\n",
        "            # rule of thumb\n",
        "            self.lag = self.order // 2\n",
        "        if self.rank_lanczos is None:\n",
        "            # rule of thumb\n",
        "            if self.n_components % 2 == 0:\n",
        "                self.rank_lanczos = 2 * self.n_components\n",
        "            else:\n",
        "                self.rank_lanczos = 2 * self.n_components - 1\n",
        "\n",
        "        assert isinstance(x, np.ndarray), \"input array must be numpy array.\"\n",
        "        assert x.ndim == 1, \"input array dimension must be 1.\"\n",
        "        assert isinstance(self.win_length, int), \"window length must be int.\"\n",
        "        assert isinstance(self.n_components, int), \"number of components must be int.\"\n",
        "        assert isinstance(self.order, int), \"order of partial time series must be int.\"\n",
        "        assert isinstance(self.lag, int), \"lag between test series and history series must be int.\"\n",
        "        assert isinstance(self.rank_lanczos, int), \"rank for lanczos must be int.\"\n",
        "        # assert self.win_length + self.order + self.lag < x.size, \"data length is too short.\"\n",
        "\n",
        "        # all values should be positive for numerical stabilization\n",
        "        # if not self.is_scaled:\n",
        "        #     x_scaled = MinMaxScaler(feature_range=(1, 2))\\\n",
        "        #         .fit_transform(x.reshape(-1, 1))[:, 0]\n",
        "        # else:\n",
        "        x_hist = x[:self.win_length-self.lag]\n",
        "        x_new = x[self.lag:]\n",
        "        score, x1 = _score_online(x_hist, x_new, x0, self.order,\n",
        "            self.win_length, self.lag, self.n_components, self.rank_lanczos,\n",
        "            self.eps, use_lanczos=self.use_lanczos)\n",
        "\n",
        "        return score, x1\n",
        "\n",
        "@jit(nopython=True)\n",
        "def _score_online(x, y, x0, order, win_length, lag, n_components, rank, eps, use_lanczos):\n",
        "    \"\"\"Core implementation of offline score calculation.\"\"\"\n",
        "    # start_idx = win_length + order + lag + 1\n",
        "    # end_idx = x.size + 1\n",
        "\n",
        "\n",
        "\n",
        "    score = np.zeros(1)\n",
        "    # for t in range(start_idx, end_idx):\n",
        "    # compute score at each index\n",
        "\n",
        "    # get Hankel matrix\n",
        "    X_history = _create_hankel(x, order,\n",
        "        start=order,\n",
        "        end=win_length-lag)\n",
        "    X_test = _create_hankel(y, order,\n",
        "        start=order,\n",
        "        end=win_length-lag)\n",
        "\n",
        "    if use_lanczos:\n",
        "        score, x1 = _sst_lanczos(X_test, X_history, n_components,\n",
        "                                      rank, x0)\n",
        "        # update initial vector for power method\n",
        "        x0 = x1 + eps * np.random.rand(x0.size)\n",
        "        x0 /= np.linalg.norm(x0)\n",
        "    else:\n",
        "        score = _sst_svd(X_test, X_history, n_components)\n",
        "\n",
        "    return score,x0\n",
        "\n",
        "@jit(nopython=True)\n",
        "def _score_offline(x, order, win_length, lag, n_components, rank, eps, use_lanczos):\n",
        "    \"\"\"Core implementation of offline score calculation.\"\"\"\n",
        "    start_idx = win_length + order + lag + 1\n",
        "    end_idx = x.size + 1\n",
        "\n",
        "    # initialize vector for power method\n",
        "    x0 = np.empty(order, dtype=np.float64)\n",
        "    x0 = np.random.rand(order)\n",
        "    x0 /= np.linalg.norm(x0)\n",
        "\n",
        "    score = np.zeros_like(x)\n",
        "    for t in range(start_idx, end_idx):\n",
        "        # compute score at each index\n",
        "\n",
        "        # get Hankel matrix\n",
        "        X_history = _create_hankel(x, order,\n",
        "            start=t - win_length - lag,\n",
        "            end=t - lag)\n",
        "        X_test = _create_hankel(x, order,\n",
        "            start=t - win_length,\n",
        "            end=t)\n",
        "\n",
        "        if use_lanczos:\n",
        "            score[t-1], x1 = _sst_lanczos(X_test, X_history, n_components,\n",
        "                                          rank, x0)\n",
        "            # update initial vector for power method\n",
        "            x0 = x1 + eps * np.random.rand(x0.size)\n",
        "            x0 /= np.linalg.norm(x0)\n",
        "        else:\n",
        "            score[t-1] = _sst_svd(X_test, X_history, n_components)\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def _create_hankel(x, order, start, end):\n",
        "    \"\"\"Create Hankel matrix.\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : full time series\n",
        "    order : order of Hankel matrix\n",
        "    start : start index\n",
        "    end : end index\n",
        "    Returns\n",
        "    -------\n",
        "    2d array shape (window length, order)\n",
        "    \"\"\"\n",
        "    win_length = end - start\n",
        "    X = np.empty((win_length, order))\n",
        "    for i in range(order):\n",
        "        X[:, i] = x[(start - i):(end - i)]\n",
        "    return X\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def _sst_lanczos(X_test, X_history, n_components, rank, x0):\n",
        "    \"\"\"Run sst algorithm with lanczos method (FELIX-SST algorithm).\"\"\"\n",
        "    P_history = X_history.T @ X_history\n",
        "    P_test = X_test.T @ X_test\n",
        "    # calculate the first singular vec of test matrix\n",
        "    u, _, _ = power_method(P_test, x0, n_iter=1)\n",
        "    T = lanczos(P_history, u, rank)\n",
        "    vec, val = eig_tridiag(T)\n",
        "    return 1 - (vec[0, :n_components] ** 2).sum(), u\n",
        "\n",
        "\n",
        "@jit(\"f8(f8[:,:],f8[:,:],u1)\", nopython=True)\n",
        "def _sst_svd(X_test, X_history, n_components):\n",
        "    \"\"\"Run sst algorithm with svd.\"\"\"\n",
        "    U_test, _, _ = np.linalg.svd(X_test, full_matrices=False)\n",
        "    U_history, _, _ = np.linalg.svd(X_history, full_matrices=False)\n",
        "    _, s, _ = np.linalg.svd(U_test[:, :n_components].T @\n",
        "        U_history[:, :n_components], full_matrices=False)\n",
        "    return 1 - s[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "username = \"test\"\n",
        "pwd = \"sensorweb\"\n",
        "\n",
        "#client = InfluxDBClient(host = 'sensorwebturing.engr.uga.edu', port = 8086, ssl=True)\n",
        "# client.switch_database(\"SaTCtestbed\")\n",
        "client = InfluxDBClient(host = 'sensorweb.us', port = 8086, username=username, password=pwd, ssl=True)\n",
        "client.switch_database(\"testdb\")\n",
        "\n",
        "currentTime = datetime.datetime.now()\n",
        "timestamp = int(currentTime.timestamp()*1000000000)\n",
        "timestamp = 1644466568662305024\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "62fcbWAjtuO7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECT \"sensor1_AC_mag\" FROM \"NI_Waveform\" WHERE  time <= 1644466568662305024 LIMIT 110\n",
            "1644484561117417216\n",
            "1644484561870845952\n",
            "1644484562616873984\n",
            "1644484563368087040\n",
            "1644484564118617088\n",
            "1644484564881440000\n",
            "1644484565627931136\n",
            "1644484566390671104\n",
            "1644484567148948992\n",
            "1644484567911955968\n",
            "1644484568662305024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\steph\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'sensorweb.us'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "##  NEED TO DEFINE \"dataCollect\"  convert from the CSV import code to influxDB queries !!!!\n",
        "\n",
        "order=50\n",
        "win_length=10\n",
        "lag=50\n",
        "pre_len = order + win_length + lag\n",
        "# pre_len = 3\n",
        "\n",
        "# get first data window\n",
        "query = f'SELECT \"sensor1_AC_mag\" FROM \"NI_Waveform\" WHERE  time <= {timestamp} LIMIT {pre_len}'\n",
        "\n",
        "#query = f'SELECT \"sensor1_AC_mag\" FROM \"NI_Waveform\" WHERE location = ''[\\'sensorweb128\\']'' AND time <= {timestamp} LIMIT {pre_len}'\n",
        "print(query)\n",
        "result = client.query(query)\n",
        "\n",
        "values = result.get_points()\n",
        "\n",
        "## Format for influxdb timestamps: \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
        "\n",
        "start_window = np.empty(pre_len)\n",
        "for point in values:\n",
        "    timeString = point['time']\n",
        "    np.append(start_window, point['sensor1_AC_mag'])\n",
        "    element = datetime.datetime.strptime(timeString,\"%Y-%m-%dT%H:%M:%S.%fZ\")  \n",
        "    endTime = int(datetime.datetime.timestamp(element)*1000000000)\n",
        "    print(endTime)\n",
        "\n",
        "# start=dataCollect[:pre_len,:]\n",
        "start=start_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Hpv9e78LCtTS"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3100/2616702440.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#x=data_arrange[:,2,i]         #### order 50, lag 50, n_components 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mscore_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingularSpectrumTransformation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwin_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_scaled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_online\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mScore_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscore_start\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mScore_start\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
          ]
        }
      ],
      "source": [
        "Score_start=np.zeros(1)\n",
        "# initialize vector for power method\n",
        "x0 = np.empty(order, dtype=np.float64)\n",
        "x0 = np.random.rand(order)\n",
        "x0 /= np.linalg.norm(x0)\n",
        "for i in [0,1,2]:  # 0,1,2,4,5,6,7,8,9\n",
        "    #x=data_arrange[:,2,i]         #### order 50, lag 50, n_components 2\n",
        "    x = start_window\n",
        "    score_start, x0 = SingularSpectrumTransformation(win_length=win_length, x0=x0, n_components=2,order=order, lag=order,is_scaled=True).score_online(start[:,i])\n",
        "    Score_start=score_start+Score_start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "KMGH9ZyXFksS",
        "outputId": "d36e4084-7ca3-46eb-f354-f0d925f3e99b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dataCollect' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22048/2772188153.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwindowSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataCollect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpre_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpre_len\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwindowSize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlastdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'dataCollect' is not defined"
          ]
        }
      ],
      "source": [
        "from scipy.fftpack.basic import ifft\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "windowSize=15000\n",
        "stream=dataCollect[pre_len:pre_len+windowSize,3]\n",
        "\n",
        "lastdata=start[:,3]\n",
        "\n",
        "Score=np.zeros(windowSize)\n",
        "var_score=np.zeros(windowSize)\n",
        "\n",
        "# det = BayesOnline()\n",
        "# for i in range(pre_len):\n",
        "#   det.find_changepoints(lastdata, 3, 0.5)\n",
        "# det.update(lastdata[i,3])\n",
        "thres1=0.4 #(normally, thres2 < thres1)\n",
        "thres2=0.05\n",
        "state=0\n",
        "move=100\n",
        "# thres=max(var_score[:4000])\n",
        "for j in range(windowSize):\n",
        "  # print(j)\n",
        "  data=np.concatenate((lastdata[1:], stream[j]), axis=None)\n",
        "  score, x0 = SingularSpectrumTransformation(win_length=win_length, x0=x0, n_components=2,order=order, lag=order,is_scaled=True).score_online(data)\n",
        "  Score[j]=score*10**5\n",
        "  lastdata=data\n",
        "  var_score[j]=50*np.var(Score[(j-move):j])\n",
        "  if var_score[j] > thres1 and state==0:   \n",
        "    print(\"At time\" , j , \", the anomaly starts\") \n",
        "    state=1 \n",
        "  elif var_score[j] < thres2 and state==1:  \n",
        "    print(\"At time\" , j , \", the anomaly ends\")\n",
        "    state=0\n",
        "  else:\n",
        "    pass\n",
        "plt.plot(Score)\n",
        "plt.plot(var_score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Online_SST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
